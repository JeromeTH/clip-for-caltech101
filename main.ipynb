{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import scipy\n",
    "import torch\n",
    "from torchvision import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# Verify the download by listing the directory contents.\n",
    "# data = datasets.Caltech101(root = \"./data\", target_type = \"category\", download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.Caltech101(root = \"./data\", target_type = \"category\", download = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Faces',\n",
       " 'Faces_easy',\n",
       " 'Leopards',\n",
       " 'Motorbikes',\n",
       " 'accordion',\n",
       " 'airplanes',\n",
       " 'anchor',\n",
       " 'ant',\n",
       " 'barrel',\n",
       " 'bass',\n",
       " 'beaver',\n",
       " 'binocular',\n",
       " 'bonsai',\n",
       " 'brain',\n",
       " 'brontosaurus',\n",
       " 'buddha',\n",
       " 'butterfly',\n",
       " 'camera',\n",
       " 'cannon',\n",
       " 'car_side',\n",
       " 'ceiling_fan',\n",
       " 'cellphone',\n",
       " 'chair',\n",
       " 'chandelier',\n",
       " 'cougar_body',\n",
       " 'cougar_face',\n",
       " 'crab',\n",
       " 'crayfish',\n",
       " 'crocodile',\n",
       " 'crocodile_head',\n",
       " 'cup',\n",
       " 'dalmatian',\n",
       " 'dollar_bill',\n",
       " 'dolphin',\n",
       " 'dragonfly',\n",
       " 'electric_guitar',\n",
       " 'elephant',\n",
       " 'emu',\n",
       " 'euphonium',\n",
       " 'ewer',\n",
       " 'ferry',\n",
       " 'flamingo',\n",
       " 'flamingo_head',\n",
       " 'garfield',\n",
       " 'gerenuk',\n",
       " 'gramophone',\n",
       " 'grand_piano',\n",
       " 'hawksbill',\n",
       " 'headphone',\n",
       " 'hedgehog',\n",
       " 'helicopter',\n",
       " 'ibis',\n",
       " 'inline_skate',\n",
       " 'joshua_tree',\n",
       " 'kangaroo',\n",
       " 'ketch',\n",
       " 'lamp',\n",
       " 'laptop',\n",
       " 'llama',\n",
       " 'lobster',\n",
       " 'lotus',\n",
       " 'mandolin',\n",
       " 'mayfly',\n",
       " 'menorah',\n",
       " 'metronome',\n",
       " 'minaret',\n",
       " 'nautilus',\n",
       " 'octopus',\n",
       " 'okapi',\n",
       " 'pagoda',\n",
       " 'panda',\n",
       " 'pigeon',\n",
       " 'pizza',\n",
       " 'platypus',\n",
       " 'pyramid',\n",
       " 'revolver',\n",
       " 'rhino',\n",
       " 'rooster',\n",
       " 'saxophone',\n",
       " 'schooner',\n",
       " 'scissors',\n",
       " 'scorpion',\n",
       " 'sea_horse',\n",
       " 'snoopy',\n",
       " 'soccer_ball',\n",
       " 'stapler',\n",
       " 'starfish',\n",
       " 'stegosaurus',\n",
       " 'stop_sign',\n",
       " 'strawberry',\n",
       " 'sunflower',\n",
       " 'tick',\n",
       " 'trilobite',\n",
       " 'umbrella',\n",
       " 'watch',\n",
       " 'water_lilly',\n",
       " 'wheelchair',\n",
       " 'wild_cat',\n",
       " 'windsor_chair',\n",
       " 'wrench',\n",
       " 'yin_yang']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = sorted(data.categories)  # Sort for consistency\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [data[i][1] for i in range(len(data))]\n",
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jerometh/miniforge3/envs/vision/lib/python3.12/site-packages/clip/clip.py:57: UserWarning: /Users/jerometh/.cache/clip/ViT-B-32.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(f\"{download_target} exists, but the SHA256 checksum does not match; re-downloading the file\")\n",
      "100%|███████████████████████████████████████| 338M/338M [00:30<00:00, 11.5MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/8677\n",
      "320/8677\n",
      "640/8677\n",
      "960/8677\n",
      "1280/8677\n",
      "1600/8677\n",
      "1920/8677\n",
      "2240/8677\n",
      "2560/8677\n",
      "2880/8677\n",
      "3200/8677\n",
      "3520/8677\n",
      "3840/8677\n",
      "4160/8677\n",
      "4480/8677\n",
      "4800/8677\n",
      "5120/8677\n",
      "5440/8677\n",
      "5760/8677\n",
      "6080/8677\n",
      "6400/8677\n",
      "6720/8677\n",
      "7040/8677\n",
      "7360/8677\n",
      "7680/8677\n",
      "8000/8677\n",
      "8320/8677\n",
      "8640/8677\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "num_images = len(data)\n",
    "image_embeddings = []\n",
    "for i in range(0, num_images, batch_size):\n",
    "    if i % (320) == 0:\n",
    "        print(f\"{i}/{num_images}\")\n",
    "    preprocessed_images = [preprocess(data[i][0]) for i in range(i, min(i+batch_size, num_images))]\n",
    "    image_batch = torch.stack(preprocessed_images).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_emb_batch = model.encode_image(image_batch).cpu()\n",
    "    image_embeddings.append(image_emb_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8677, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_embeddings = torch.cat(image_embeddings)\n",
    "image_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClipEmbeddingsDataset(Dataset):\n",
    "    def __init__(self, image_embeddings, labels):\n",
    "        self.image_embeddings = image_embeddings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_embeddings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.image_embeddings[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 3.5840e-02, -1.6151e-01, -3.0853e-01, -7.1587e-01, -5.9231e-02,\n",
       "          4.3419e-02,  1.0449e-01,  6.7824e-01,  5.1617e-01,  6.1116e-01,\n",
       "          3.2395e-02, -1.3369e-01,  2.3393e-01, -4.5477e-01, -5.9802e-01,\n",
       "          7.1524e-02,  9.0372e-01,  4.9348e-01,  5.6496e-02,  5.2156e-01,\n",
       "         -7.3129e-01,  1.3309e-01, -4.1486e-01, -4.9551e-01,  2.3558e-01,\n",
       "          3.8464e-01, -1.5420e-01, -4.8332e-01,  1.9169e-01, -2.1391e-01,\n",
       "          5.5755e-02, -4.0705e-01,  5.8370e-01, -1.6488e-02,  1.1376e-01,\n",
       "         -3.4988e-01,  4.0409e-02, -8.9154e-02,  2.6772e-01,  3.4514e-01,\n",
       "         -5.1853e-01,  3.5546e-01,  7.8249e-01,  5.1927e-02,  8.3776e-02,\n",
       "         -1.7630e+00,  5.9644e-03, -1.8441e-02,  5.7882e-01, -2.2634e-01,\n",
       "         -2.9172e-01,  2.3713e-01,  6.4021e-02, -3.9163e-01, -1.0326e-01,\n",
       "         -1.6542e-02, -3.1119e-02, -4.5635e-01, -1.7915e-01, -5.9720e-01,\n",
       "          6.0462e-01, -2.6313e-01, -5.2777e-01, -4.9555e-01, -3.1327e-01,\n",
       "          2.8816e-02, -1.1795e-01, -3.1599e-01,  1.5970e-01,  3.2195e-01,\n",
       "         -2.9791e-01,  2.1005e-01, -2.0954e-01, -3.0631e-01,  5.4415e-01,\n",
       "         -7.1495e-01, -2.2885e-01, -1.2929e-01,  4.8576e-02, -4.0823e-01,\n",
       "         -1.7140e-02,  1.2591e-02, -4.1337e-01, -1.2997e+00, -5.0100e-01,\n",
       "          4.8522e-01,  1.3124e+00, -8.7885e-02,  3.4409e-01, -2.4306e-01,\n",
       "          2.8267e-01, -1.2232e-01, -7.5897e+00,  6.3170e-01,  1.3284e-01,\n",
       "          2.2472e-01,  3.3298e-01,  7.5284e-02, -7.5145e-01,  5.9010e-01,\n",
       "         -2.1881e-01, -1.8457e-01,  4.4136e-02,  2.0778e-01, -2.2945e-01,\n",
       "          2.5094e-01, -2.7600e+00,  9.2165e-02,  3.3646e-01,  1.5056e-01,\n",
       "         -1.9377e-02,  4.3172e-01, -6.5227e-02,  4.8552e-01, -8.5231e-03,\n",
       "          1.3255e-02,  7.5231e-01,  1.7515e-01,  1.8429e-01,  6.6285e-01,\n",
       "         -4.9788e-02, -4.0731e-01, -3.4860e-01,  1.1645e-01,  3.2849e-02,\n",
       "          3.8337e-01, -3.1789e-01, -3.6857e-02, -1.7544e-01, -2.0336e-01,\n",
       "          5.1612e-01, -4.5528e-01, -4.2237e-01,  9.2341e-01,  2.5742e-01,\n",
       "          3.5989e-01, -1.6474e-01, -6.9503e-01, -3.8202e-02, -3.8953e-01,\n",
       "          9.7856e-02,  3.8460e-01, -5.6785e-01,  5.9496e-01, -2.3884e-01,\n",
       "         -1.8271e-01,  3.1757e-01, -2.6691e-02,  1.8041e-01, -4.3393e-02,\n",
       "         -2.4153e-01, -4.9549e-01, -3.0666e-01, -7.0534e-01,  3.7038e-01,\n",
       "         -5.4989e-01,  8.4242e-02, -2.4111e-01, -3.1544e-01,  1.0389e-01,\n",
       "         -1.3363e-01, -5.7062e-02, -7.2247e-02,  1.3645e-01, -6.3003e-01,\n",
       "         -1.2445e-01, -5.4408e-01, -2.4761e-01, -3.1547e-02, -3.4914e-02,\n",
       "         -4.1782e-03, -1.9282e-01, -3.6684e-02, -3.0250e-03, -3.9741e-01,\n",
       "         -2.7547e-01, -3.2725e-01, -7.2597e-02, -5.3003e-01,  2.7963e-01,\n",
       "         -1.4549e-01,  1.7756e-01,  8.3061e-02,  3.5569e-01, -1.0142e-02,\n",
       "         -2.8241e-01, -1.1415e-01, -5.6466e-01,  2.3497e-01, -1.9325e-01,\n",
       "         -2.0751e-01, -1.6027e-01,  2.0611e-01, -2.6691e-01,  7.9154e-01,\n",
       "          6.0542e-02, -4.0823e-02, -9.2717e-02,  1.4250e-01, -7.4650e-01,\n",
       "         -2.6731e-02, -1.0168e-01, -1.2650e-01,  6.9162e-03,  5.4895e-01,\n",
       "          7.3655e-02,  6.6971e-02, -3.1910e-02,  6.5612e-01, -3.1767e-01,\n",
       "          3.9547e-02,  3.6966e-01, -1.1094e-01, -2.0981e-01,  3.7248e-01,\n",
       "          4.7782e-01,  2.3073e-01, -6.9224e-01, -6.1270e-01, -2.4653e-02,\n",
       "          5.9263e-01, -1.3022e-01,  3.4088e-01, -2.2390e-01,  1.1694e-01,\n",
       "         -2.5190e-01, -2.9854e-01, -2.7398e-01,  2.7010e-01, -3.1364e-01,\n",
       "         -3.3905e-01, -1.9318e-01, -8.1608e-03,  4.2651e-01,  5.3710e-01,\n",
       "          3.1222e-01,  8.9886e-02,  2.0182e-01, -4.0126e-01,  2.7917e-01,\n",
       "         -2.8167e-01, -2.6545e-01,  4.5314e-02,  1.1265e-01, -3.5493e-03,\n",
       "         -2.4345e-03,  6.1809e-01, -3.9456e-01, -6.8416e-02,  9.0918e-02,\n",
       "          7.5234e-02,  5.9476e-01,  6.0124e-01,  1.1549e-01, -9.6418e-02,\n",
       "         -8.7321e-02,  2.2935e-01,  2.5663e-01, -1.4243e-01, -3.9718e-01,\n",
       "          3.2188e-02,  3.7725e-01,  3.2023e-01, -6.3881e-01,  2.5732e-01,\n",
       "          2.0769e-01,  3.8903e-01,  8.6387e-02, -1.3141e-02, -5.8471e-02,\n",
       "          3.0903e-01,  2.9124e-01, -1.9800e-01,  8.8498e-02,  4.4839e-02,\n",
       "         -2.9917e-01, -2.2630e-01,  1.1468e-01, -1.4346e-02,  5.2747e-02,\n",
       "         -1.5656e-02,  1.3510e-01,  8.8439e-02,  5.5003e-02, -1.0015e-02,\n",
       "         -2.8731e-01, -7.1822e-01, -6.4139e-01, -8.9645e-02,  5.8146e-02,\n",
       "          3.1265e-01, -4.4659e-01, -2.1093e-01, -7.5341e-02,  5.0538e-01,\n",
       "         -2.9589e-01,  8.0676e-01, -1.8100e-01,  1.8135e-01,  6.2359e-01,\n",
       "         -1.3652e-01,  1.4927e-01,  4.1015e-01,  8.9485e-02,  1.3742e-01,\n",
       "          2.3315e-02, -8.1755e-01,  9.1743e-02,  1.5346e-02,  1.5982e-01,\n",
       "         -1.7239e-01, -6.5600e-01,  9.2245e-01,  4.1542e-01,  1.9928e-01,\n",
       "         -3.4212e-01, -4.7225e-02,  2.8745e-01, -2.4959e-01, -9.7178e-01,\n",
       "          3.3900e-01,  2.2329e+00, -2.1438e-01,  3.4525e-02, -2.8275e-01,\n",
       "         -1.7993e-01, -3.6619e-01,  2.9051e-01,  5.9868e-02,  2.9362e-01,\n",
       "         -5.1687e-01,  4.3869e-02,  4.1586e-01, -1.1095e-01, -2.6697e-01,\n",
       "         -4.7995e-01, -2.9796e-01, -5.6904e-02,  3.5824e-02,  6.7347e-01,\n",
       "          5.5284e-01, -2.6849e-01,  7.0173e-02,  3.1543e-01, -3.0679e-01,\n",
       "         -4.7438e-01, -8.6673e-02,  9.6890e-02, -4.3617e-01, -1.4556e-01,\n",
       "          1.4575e-01, -2.2200e-01,  5.5110e-01, -1.2412e-01, -5.5889e-02,\n",
       "         -1.9028e-01,  3.4448e-02, -6.9033e-01,  3.2999e-01, -7.9800e-02,\n",
       "          4.0465e-01, -1.3392e-01,  1.4317e-02, -3.0772e-01, -3.6829e-01,\n",
       "         -2.0044e-01,  6.9680e-02, -1.3504e+00, -1.3746e-01, -7.5430e-03,\n",
       "          1.0422e-01,  6.9614e-02,  5.8736e-02,  7.8343e-02,  2.2228e-01,\n",
       "          1.8812e-01,  4.2547e-02,  8.2384e-02, -2.9364e-01, -3.2326e-01,\n",
       "         -1.3728e-01,  4.8878e-02, -3.6076e-01, -1.0713e-01,  1.5883e-01,\n",
       "         -1.9648e-01, -1.0212e-03,  2.7866e-01, -4.4677e-02,  2.7311e-01,\n",
       "         -3.8519e-01,  2.8497e-01, -1.0200e-01,  5.8963e-02, -1.4344e-01,\n",
       "         -2.2628e-01,  5.0946e-01,  4.6317e-01, -2.4778e-01, -5.0081e-01,\n",
       "         -2.7433e-01, -2.8214e-01,  2.3127e-01,  3.4115e-01,  2.7730e-01,\n",
       "         -3.3531e-01, -2.3715e-01,  4.1497e-02, -4.8849e-02,  5.2644e-02,\n",
       "          2.6446e-01,  4.0742e-02,  5.9123e-01,  4.5980e-01, -4.9149e-01,\n",
       "          4.1961e-01,  6.1363e-01,  3.4301e-02, -2.7369e-01,  2.2329e-01,\n",
       "         -2.8261e-02, -7.1549e-02, -5.0036e-01,  4.9774e-02, -1.0006e-01,\n",
       "         -3.3899e-01,  1.1087e-01, -1.3399e-02,  2.0022e-01, -2.1259e-01,\n",
       "         -2.0513e-01, -4.2214e-02,  5.8808e-01, -1.4060e-01, -9.5958e-02,\n",
       "         -9.3314e-02, -9.0955e-02, -1.8258e-01, -2.1437e-01, -6.1373e-02,\n",
       "          2.1679e-01,  9.9331e-02, -2.6930e-01, -1.9984e-01,  3.9806e-01,\n",
       "         -9.3832e-02, -1.5164e-01, -2.5011e-01, -2.5311e-01,  1.9767e-01,\n",
       "         -1.7553e-01,  2.6337e-01,  1.5930e-01, -1.1909e+00,  3.1092e-01,\n",
       "         -3.0903e-01,  4.8745e-01,  3.7015e-01, -2.3783e-01,  2.9910e-03,\n",
       "          3.3318e-01,  3.4894e-01, -2.0951e-01, -3.4859e-02,  3.7205e-01,\n",
       "         -1.2002e-01, -1.7116e-01,  1.5305e-01,  3.5492e-03,  3.1321e-01,\n",
       "         -3.6632e-01,  5.9155e-02,  1.8206e-01, -3.5220e-01, -3.9845e-02,\n",
       "          2.4987e-01, -2.2977e-01, -3.6546e-01, -5.4632e-02, -1.5451e-02,\n",
       "          1.4429e-01, -1.0893e-01,  2.3950e-01, -3.5538e-01, -3.4697e-01,\n",
       "         -2.4175e-01,  2.9393e-01,  1.9272e-02, -1.9679e-01,  1.2913e-01,\n",
       "         -5.0367e-01, -1.1352e-01, -1.9862e-01, -1.8794e-01, -4.7766e-02,\n",
       "          1.6029e-01, -2.1236e-01,  7.6961e-02,  2.5775e-01, -1.9755e-01,\n",
       "          1.2962e-01,  1.1457e-01, -2.2720e-01,  3.5132e-01, -1.5757e-01,\n",
       "         -5.1437e-01, -2.2328e-01,  2.3547e-01, -4.9690e-01,  1.3607e-01,\n",
       "          1.3228e-01, -8.7449e-04]),\n",
       " 92)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dataset = ClipEmbeddingsDataset(image_embeddings, labels)\n",
    "embeddings_dataset.__getitem__(8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into train and test\n",
    "train_size = int(0.8 * len(embeddings_dataset))\n",
    "test_size = len(embeddings_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(embeddings_dataset, [train_size, test_size])\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataloader.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(512, 256)\n",
    "        self.layer2 = nn.Linear(256, 256)\n",
    "        self.layer3 = nn.Linear(256, 101)\n",
    "        self._init_weights()\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)  # Applies Xavier initialization\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)  # Sets biases to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Epoch [1/100], Loss: 2.9809\n",
      "Epoch [2/100], Loss: 1.3570\n",
      "Epoch [3/100], Loss: 0.6709\n",
      "Epoch [4/100], Loss: 0.4299\n",
      "Epoch [5/100], Loss: 0.3179\n",
      "Epoch [6/100], Loss: 0.2513\n",
      "Epoch [7/100], Loss: 0.2126\n",
      "Epoch [8/100], Loss: 0.1807\n",
      "Epoch [9/100], Loss: 0.1588\n",
      "Epoch [10/100], Loss: 0.1418\n",
      "Epoch [11/100], Loss: 0.1278\n",
      "Epoch [12/100], Loss: 0.1172\n",
      "Epoch [13/100], Loss: 0.1053\n",
      "Epoch [14/100], Loss: 0.0958\n",
      "Epoch [15/100], Loss: 0.0901\n",
      "Epoch [16/100], Loss: 0.0804\n",
      "Epoch [17/100], Loss: 0.0748\n",
      "Epoch [18/100], Loss: 0.0700\n",
      "Epoch [19/100], Loss: 0.0663\n",
      "Epoch [20/100], Loss: 0.0606\n",
      "Epoch [21/100], Loss: 0.0584\n",
      "Epoch [22/100], Loss: 0.0535\n",
      "Epoch [23/100], Loss: 0.0534\n",
      "Epoch [24/100], Loss: 0.0467\n",
      "Epoch [25/100], Loss: 0.0459\n",
      "Epoch [26/100], Loss: 0.0429\n",
      "Epoch [27/100], Loss: 0.0419\n",
      "Epoch [28/100], Loss: 0.0386\n",
      "Epoch [29/100], Loss: 0.0378\n",
      "Epoch [30/100], Loss: 0.0352\n",
      "Epoch [31/100], Loss: 0.0336\n",
      "Epoch [32/100], Loss: 0.0335\n",
      "Epoch [33/100], Loss: 0.0303\n",
      "Epoch [34/100], Loss: 0.0302\n",
      "Epoch [35/100], Loss: 0.0281\n",
      "Epoch [36/100], Loss: 0.0277\n",
      "Epoch [37/100], Loss: 0.0255\n",
      "Epoch [38/100], Loss: 0.0260\n",
      "Epoch [39/100], Loss: 0.0240\n",
      "Epoch [40/100], Loss: 0.0243\n",
      "Epoch [41/100], Loss: 0.0224\n",
      "Epoch [42/100], Loss: 0.0212\n",
      "Epoch [43/100], Loss: 0.0218\n",
      "Epoch [44/100], Loss: 0.0209\n",
      "Epoch [45/100], Loss: 0.0208\n",
      "Epoch [46/100], Loss: 0.0197\n",
      "Epoch [47/100], Loss: 0.0188\n",
      "Epoch [48/100], Loss: 0.0186\n",
      "Epoch [49/100], Loss: 0.0194\n",
      "Epoch [50/100], Loss: 0.0172\n",
      "Epoch [51/100], Loss: 0.0169\n",
      "Epoch [52/100], Loss: 0.0169\n",
      "Epoch [53/100], Loss: 0.0170\n",
      "Epoch [54/100], Loss: 0.0155\n",
      "Epoch [55/100], Loss: 0.0156\n",
      "Epoch [56/100], Loss: 0.0148\n",
      "Epoch [57/100], Loss: 0.0155\n",
      "Epoch [58/100], Loss: 0.0153\n",
      "Epoch [59/100], Loss: 0.0153\n",
      "Epoch [60/100], Loss: 0.0148\n",
      "Epoch [61/100], Loss: 0.0132\n",
      "Epoch [62/100], Loss: 0.0141\n",
      "Epoch [63/100], Loss: 0.0139\n",
      "Epoch [64/100], Loss: 0.0124\n",
      "Epoch [65/100], Loss: 0.0121\n",
      "Epoch [66/100], Loss: 0.0122\n",
      "Epoch [67/100], Loss: 0.0106\n",
      "Epoch [68/100], Loss: 0.0122\n",
      "Epoch [69/100], Loss: 0.0109\n",
      "Epoch [70/100], Loss: 0.0118\n",
      "Epoch [71/100], Loss: 0.0112\n",
      "Epoch [72/100], Loss: 0.0105\n",
      "Epoch [73/100], Loss: 0.0099\n",
      "Epoch [74/100], Loss: 0.0097\n",
      "Epoch [75/100], Loss: 0.0102\n",
      "Epoch [76/100], Loss: 0.0105\n",
      "Epoch [77/100], Loss: 0.0093\n",
      "Epoch [78/100], Loss: 0.0096\n",
      "Epoch [79/100], Loss: 0.0096\n",
      "Epoch [80/100], Loss: 0.0087\n",
      "Epoch [81/100], Loss: 0.0089\n",
      "Epoch [82/100], Loss: 0.0093\n",
      "Epoch [83/100], Loss: 0.0092\n",
      "Epoch [84/100], Loss: 0.0095\n",
      "Epoch [85/100], Loss: 0.0080\n",
      "Epoch [86/100], Loss: 0.0088\n",
      "Epoch [87/100], Loss: 0.0090\n",
      "Epoch [88/100], Loss: 0.0077\n",
      "Epoch [89/100], Loss: 0.0080\n",
      "Epoch [90/100], Loss: 0.0084\n",
      "Epoch [91/100], Loss: 0.0078\n",
      "Epoch [92/100], Loss: 0.0084\n",
      "Epoch [93/100], Loss: 0.0077\n",
      "Epoch [94/100], Loss: 0.0083\n",
      "Epoch [95/100], Loss: 0.0058\n",
      "Epoch [96/100], Loss: 0.0082\n",
      "Epoch [97/100], Loss: 0.0075\n",
      "Epoch [98/100], Loss: 0.0065\n",
      "Epoch [99/100], Loss: 0.0076\n",
      "Epoch [100/100], Loss: 0.0054\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "model = NeuralNet()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "model = model.to(device)\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "n_epochs= 100\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()  # Add the loss value for monitoring\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {running_loss/len(train_dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 512]), tensor([94,  0, 45, 50,  1, 92, 71,  5,  3, 53]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input, label = next(iter(train_dataloader))\n",
    "input.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -6.3651,  -2.2537,  -3.9694,  ...,  -4.5904,   6.2325,   3.2399],\n",
       "        [ 19.9324,   8.4823,  -1.3478,  ...,  -2.6515,   4.0993,  -1.7972],\n",
       "        [ -3.3025,  -3.6270,  -6.5164,  ...,   2.1753,  -3.0322,   1.5346],\n",
       "        ...,\n",
       "        [  1.4780,  -6.7455,   1.7283,  ..., -11.5951,   2.0453,  -4.8570],\n",
       "        [ -2.1178,  -5.4750,   1.2461,  ...,  -1.3860,  -3.4950,  -7.7456],\n",
       "        [  3.1898,  -4.4681,   2.1757,  ...,  -1.0387,  -1.9317,  -3.8632]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input)\n",
    "output\n",
    "# torch.argmax(model(input), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run inference on test_dataloader\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9585253456221198\n",
      "1736\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
